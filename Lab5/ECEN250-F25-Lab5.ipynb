{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr9QLBDOyg2V"
      },
      "source": [
        "# Part 1: Understanding Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0gEGxSmyl_h"
      },
      "source": [
        "The goal of this part is to understand how logistic regression handle binary classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UCErMGIy186"
      },
      "source": [
        "We will be using Python libraries such as numpy, matplotlib, scipy, and sklearn. Make sure all these are imported to run the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN9OMzGFygOn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.special import expit  # Sigmoid function\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVYRYis4zL5J"
      },
      "source": [
        "We will create a simple toy dataset where the X values are sampled from a Gaussian distribution (normal distribution) with some added noise. The target y will be a binary value (0 or 1), based on whether X is greater than zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWfcFxFRzZFl"
      },
      "outputs": [],
      "source": [
        "xmin, xmax = -5, 5\n",
        "n_samples = 1000  # Number of samples\n",
        "np.random.seed(1)\n",
        "X = np.random.normal(size=n_samples)\n",
        "y = (X > 0).astype(float)  # Binary classification target\n",
        "\n",
        "X[X > 0] *= 4  # Scale positive values\n",
        "X += 0.3 * np.random.normal(size=n_samples)  # Add noise\n",
        "\n",
        "X = X[:, np.newaxis]  # Reshape X for sklearn compatibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbA0fT8O2499"
      },
      "outputs": [],
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8XedowJ0jb0"
      },
      "outputs": [],
      "source": [
        "# Visualize the dataset\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P0S_dl81NvU"
      },
      "source": [
        "Next, we fit a logistic regression model to the data. Logistic regression models the probability that `y=1` given `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM47kZJs1M_2"
      },
      "outputs": [],
      "source": [
        "logistic_regr = LogisticRegression(C=1e5)  # C=1e5 minimizes regularization to fit more closely\n",
        "logistic_regr.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsM9FmFm3lhH"
      },
      "source": [
        "The logistic function is of the form:\n",
        "$$p = \\frac{1}{1+e^{-(ax+b)}}$$,\n",
        "where $a$ is the coefficient and $b$ is the intercept.  \n",
        "$p$ gives the probability that $y=1$ given $x$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhD_Fwn3g3fC"
      },
      "source": [
        "Print the coefficient and the intercept of the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZIGCGBP4lzh"
      },
      "outputs": [],
      "source": [
        "print(\"Coefficient (a):\", logistic_regr.coef_[0][0])\n",
        "print(\"Intercept (b):\", logistic_regr.intercept_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWjCwkpXvPIc"
      },
      "source": [
        "**Open a code cell below, calculate the value of $x$ that gives $p=0.5$.  \n",
        "Assign this value to the variable `x_threshold`.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woqK1g2f_IqT"
      },
      "source": [
        "Now let's plot the logistic regression model, along with its prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Nw2hFJTw9F6"
      },
      "outputs": [],
      "source": [
        "y_pred = logistic_regr.predict(X)\n",
        "\n",
        "# Create a range of x values for plotting\n",
        "x_plot = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "# Calculate the predicted probabilities using the logistic regression model\n",
        "p_plot = 1 / (1 + np.exp(-(logistic_regr.coef_[0][0] * x_plot + logistic_regr.intercept_[0])))\n",
        "\n",
        "# Plot the logistic function\n",
        "plt.plot(x_plot, p_plot, label=\"Logistic Regression\", c='orange')\n",
        "plt.scatter(X, y_pred, label=\"Logistic Regression Predictions\", c='blue')\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot dashed lines where p = 0.5, x = x_threshold\n",
        "plt.axhline(0.5, linestyle='--')\n",
        "plt.axvline(x_threshold, linestyle='--')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Ar2v_Ky9dJ"
      },
      "source": [
        "**Open a text cell below, and answer the question:  \n",
        "How does logistic regression determine the decision boundary between class 0 and class 1?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kOa0KS71QNL"
      },
      "source": [
        "Now let's compare the prediction with the original dataset (ground truth)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry--I3En5_Sa"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# Create a range of x values for plotting\n",
        "x_plot = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "# Calculate the predicted probabilities using the logistic regression model\n",
        "p_plot = 1 / (1 + np.exp(-(logistic_regr.coef_[0][0] * x_plot + logistic_regr.intercept_[0])))\n",
        "\n",
        "# Plot the logistic function\n",
        "ax[0].plot(x_plot, p_plot, c='orange')\n",
        "ax[0].scatter(X, y, label=\"Ground truth\")\n",
        "ax[0].set_xlabel(\"X\")\n",
        "ax[0].set_ylabel(\"y\")\n",
        "ax[0].axhline(0.5, linestyle='--')\n",
        "ax[0].axvline(x_threshold, linestyle='--')\n",
        "ax[0].legend(loc='lower right')\n",
        "\n",
        "ax[1].plot(x_plot, p_plot, c='orange')\n",
        "ax[1].scatter(X, y_pred, label=\"Predictions\", c='blue')\n",
        "ax[1].set_xlabel(\"X\")\n",
        "ax[1].set_ylabel(\"y\")\n",
        "ax[1].axhline(0.5, linestyle='--')\n",
        "ax[1].axvline(x_threshold, linestyle='--')\n",
        "ax[1].legend(loc='lower right')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNBGXcxF3hCk"
      },
      "source": [
        "**Open a text cell below, and answer the question:  \n",
        "Does the logistic regression model give 100% accuracy for this dataset? Justify your answer.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii7zN7aN4UZ-"
      },
      "source": [
        "# Part 2: Comparing Logistic Regression with Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkuxyp2b7Zbk"
      },
      "source": [
        "Using the same datset, let's create a linear regression model.  \n",
        "**Insert a code cell below, add code to create a linear regression model `linear_regr`, and fit the model with the dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGlO_-O_ZY_"
      },
      "source": [
        "**Open a text cell below, and answer the question:  \n",
        "What assumptions does linear regression make about the relationship between X and y?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lQxfWWlAKXB"
      },
      "source": [
        "**Open a code cell below, print the coefficient and intercept of the linear regression model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvJur6e-_y09"
      },
      "source": [
        "We now plot both the logistic regression model and the linear regression model on the same graph to compare them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlhJUW4O_jYJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(1, figsize=(8, 6))  # Set up figure\n",
        "plt.scatter(X, y, label=\"Example data\", color=\"blue\", s=20, marker = 'o')  # Scatter plot of the data\n",
        "\n",
        "X_test = np.linspace(-5, 10, 300)  # Test range for X-axis\n",
        "\n",
        "# Logistic regression prediction (sigmoid curve)\n",
        "loss = expit(X_test * logistic_regr.coef_ + logistic_regr.intercept_).ravel()\n",
        "plt.plot(X_test, loss, label=\"Logistic Regression Model\", color=\"orange\", linewidth=2)\n",
        "\n",
        "# Linear regression prediction (straight line)\n",
        "plt.plot(\n",
        "    X_test,\n",
        "    linear_regr.coef_ * X_test + linear_regr.intercept_,\n",
        "    label=\"Linear Regression Model\",\n",
        "    linewidth=2,\n",
        ")\n",
        "\n",
        "plt.axhline(0.5, color=\".5\")  # Horizontal line at y=0.5\n",
        "plt.ylabel(\"y\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylim(-0.5, 1.5)  # Set y-limits\n",
        "plt.xlim(-4, 10)  # Set x-limits\n",
        "\n",
        "plt.legend(loc=\"lower right\", fontsize=\"small\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K2piX1WCNLM"
      },
      "source": [
        "**Open a text cell below, and answer the questions:**\n",
        "1. What do you observe about the shape of the logistic regression curve compared to the linear regression line?\n",
        "2. Why does logistic regression's output stay between 0 and 1, whereas linear regression does not?\n",
        "3. If you were to classify the data into two groups based on the output of the linear regression model, what threshold would you use? How would this threshold compare to the 0.5 threshold in logistic regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku2rRwzKDtjd"
      },
      "source": [
        "# Part 3:Customer Churn Prediction (Binary Classification)\n",
        "\n",
        "In this part of the lab, you will build a logistic regression model to predict customer churn (whether a customer will leave a service). This is a typical binary classification problem. The task will use a dataset with various customer features, and the goal is to predict whether a customer will churn or not (0 = no churn, 1 = churn).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft9HaGaibY2T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Sklearn imports\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTOa6PWVbfou"
      },
      "outputs": [],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLrnYzvNbr6l"
      },
      "outputs": [],
      "source": [
        "!ls drive/MyDrive/ECEN250/lab5_logistic_regression/Telco_Customer_Churn.csv ## please change this to the directory of your own csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVJQUWiiRMwo"
      },
      "source": [
        "Load the dataset and perform some basic exploratory data analysis to understand its structure and key characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLkeyEvabcHJ"
      },
      "outputs": [],
      "source": [
        "# importing dataset\n",
        "df = pd.read_csv('drive/MyDrive/ECEN250/lab5_logistic_regression/Telco_Customer_Churn.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TRy2OTVcVuo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_vtfeFscaA3"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wftjrJhBldxh"
      },
      "source": [
        "Column `TotalCharges` is of type `object`, there might be some non-numeric values.  \n",
        "Let's try to convert column `TotalCharges` to numeric using `pd.to_numeric()`, and set `errors='coerce'` to turn non-numeric values into NaN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSTpDWhyl26t"
      },
      "outputs": [],
      "source": [
        "# Convert the TotalCharges column to numeric, forcing errors to NaN\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVmM8gGkr0it"
      },
      "source": [
        "Check the datatype of this column again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdQFb_5lr3Cj"
      },
      "outputs": [],
      "source": [
        "print(df['TotalCharges'].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRKLc4PsD7x"
      },
      "source": [
        "**Insert a code block below to drop the NaNs in the dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk2Jy0zxPtch"
      },
      "outputs": [],
      "source": [
        "# Reset row index after drop some rows\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcgn4on4cjRW"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZzUld63tzra"
      },
      "source": [
        "**Open a code cell below to drop the column 'customerID', since it's not relevant for predicting customer churn.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7zkHaUJtUrk"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKID6PQtwtZT"
      },
      "source": [
        "Check the values in column `Churn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BZHhqy-wker"
      },
      "outputs": [],
      "source": [
        "df['Churn'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHTuDikzvbbK"
      },
      "source": [
        "Column `Churn` contains values of `No` or `Yes`. Let's convert them to numerical values `0` or `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCrC-1mnvqIi"
      },
      "outputs": [],
      "source": [
        "# Convert 'Churn' column to numerical values: No -> 0, Yes -> 1\n",
        "df['Churn'] = df['Churn'].replace({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Verify the datatype of 'Churn' column\n",
        "df['Churn'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWksUEzzzDr6"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvwhK50vtDkk"
      },
      "source": [
        "Let's start with a logistic regresion model with only one feature.  \n",
        "**Use the TotalCharges feature to predict customer churn. Insert code cells below, create a dataset (X, y) with this feature, and Churn as label. Split the dataset into 70% training and 30% testing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybaiPaNujhZ"
      },
      "source": [
        "**Insert a code cell below. Create a logistic regression model, train the model with the training set, and predict on the testing set.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usJnZ1hyvORm"
      },
      "source": [
        "Let's look at the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJgMZIfevRWr"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKHRD7VU1kkD"
      },
      "source": [
        "**Question: Compared with the accuracy score, how does the confusion matrix help you understand the model's performance?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLMvkLRrxIal"
      },
      "source": [
        "Now we use all numerical columns in the original dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdd5HGnIy1t4"
      },
      "outputs": [],
      "source": [
        "df_numerical = df.select_dtypes(include=['int64', 'float64'])\n",
        "df_numerical.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Vscoduxhsr"
      },
      "source": [
        "**Insert code cells below and do the following:   \n",
        "Create a dataset with the above numerical feature. Split the dataset into 70% training and 30% testing.  \n",
        "Create a logistic regression model, train the model with the training set, and predict on the testing set.  \n",
        "Calculate the prediction accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7akAIXZyBnf"
      },
      "source": [
        "**Question: Is the performance improved compared with the previous model with only one feature? Justify your answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J48TXIYyMos"
      },
      "source": [
        "Now let's use all the features in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5SvoshLw2xR"
      },
      "outputs": [],
      "source": [
        "# Loop through all columns with 'object' dtype\n",
        "for column in df.select_dtypes(include='object').columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values in '{column}' column: {unique_values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9CyQaxfyYnN"
      },
      "source": [
        "The following code converts all categorical columns into numerical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOKGQf7bDsfz"
      },
      "outputs": [],
      "source": [
        "categorical_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
        "df_categorical = df[categorical_cols].copy()\n",
        "for col in categorical_cols:\n",
        "    if df_categorical[col].nunique() == 2:\n",
        "        df_categorical[col], _ = pd.factorize(df_categorical[col])\n",
        "    else:\n",
        "        df_categorical = pd.get_dummies(df_categorical, columns=[col])\n",
        "\n",
        "df_categorical = df_categorical.astype('int')\n",
        "\n",
        "\n",
        "df_categorical.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xDOtt-nEd9V"
      },
      "outputs": [],
      "source": [
        "df_categorical.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb1kP_2_GX1B"
      },
      "outputs": [],
      "source": [
        "df_numerical.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDudO54gyuz5"
      },
      "source": [
        "Apply a standard scaler to the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA5kFXMpF-ik"
      },
      "outputs": [],
      "source": [
        "numerical_cols = [col for col in df.columns if df[col].dtype != 'object' and col!='Churn']\n",
        "df_std = pd.DataFrame(StandardScaler().fit_transform(df_numerical[numerical_cols].astype('float64')), columns=numerical_cols)\n",
        "df_std.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf1pcKElGbRG"
      },
      "outputs": [],
      "source": [
        "df_std.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_YSk2jAy9NL"
      },
      "source": [
        "Combine the numerical and categorical columns together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4uZY4ajEhY1"
      },
      "outputs": [],
      "source": [
        "df_processed = pd.concat([df_std, df_categorical], axis=1)\n",
        "df_processed['Churn'] = df_numerical['Churn'].astype(int)\n",
        "df_processed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGigde5LEtZH"
      },
      "outputs": [],
      "source": [
        "df_processed.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VXB5AGIzByL"
      },
      "source": [
        "**Insert code cells below and do the following:   \n",
        "Create a dataset using a above dataframe, with `Churn` as label, and all other columns as feature.  \n",
        "Split the dataset into 70% training and 30% testing.  \n",
        "Create a logistic regression model, train the model with the training set, and predict on the testing set.  \n",
        "Calculate the prediction accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZd8jluAzVKt"
      },
      "source": [
        "**Question: Open a text cell below, summarize and compare the performance of 1. model with only one feature; 2. model with four numerical features; 3. model with all features. Please share your observation and insights.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lab 5 is now complete.  Make sure all cells are visible and have been run (rerun if necessary).\n",
        "\n",
        "The code below converts the ipynb file to PDF, and saves it to where this .ipynb file is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NOTEBOOK_PATH = # Enter here, the path to your notebook file, e.g. \"/content/drive/MyDrive/ECEN250/ECEN250_Lab5.ipynb\". Do not change the lines below, and make sure you do not have multiple notebooks with the same path.\n",
        "! pip install playwright\n",
        "! jupyter nbconvert --to webpdf --allow-chromium-download \"$NOTEBOOK_PATH\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download your notebook as an .ipynb file, then upload it along with the PDF file (saved in the same Google Drive folder as this notebook) to Canvas for Lab 5. Make sure that the PDF file matches your .ipynb file."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

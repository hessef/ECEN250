{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzZHEcNrwsCp"
      },
      "source": [
        "## Part 1: Regression Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z8tKV0Sw4gk"
      },
      "source": [
        "We need to import our libraries, including the linear regression models.  We will also need train_test_split to divide data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HdDk4Ccq7Ai"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OB0gA-7xaip"
      },
      "source": [
        "Let's do some examples of regression examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6-sTb3AxWGe"
      },
      "outputs": [],
      "source": [
        "X = np.array([[1], [4], [0], [3]])\n",
        "y = np.array([[5.7], [10], [2.6], [9.3]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hFqGMO-L8N2"
      },
      "source": [
        "Build a regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhCSo8Vl6FwK"
      },
      "outputs": [],
      "source": [
        "reg =LinearRegression().fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U96SP3oL-fC"
      },
      "source": [
        "Show the R-2 goodness of fit. Recall R-2 (r-square) is the ratio of the variance that is explainable with our model divided by the total variance.  R-2 should approach 1.0 for a good model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4zitNkw8W4Y"
      },
      "outputs": [],
      "source": [
        "reg.score(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqzIA32fMCkF"
      },
      "source": [
        "Show the weights -- X weight and the Intercept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRrfxF5l8YPx"
      },
      "outputs": [],
      "source": [
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOlSSnom8Zux"
      },
      "outputs": [],
      "source": [
        "reg.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q61qPbBxSCT"
      },
      "source": [
        "**Open a text cell after this one and give the equation for the regression for this example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNoTEsImMPXH"
      },
      "source": [
        "Predict on new observations. We use a different set of observations (test set) to evaluate our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PhrH5Hojng9"
      },
      "outputs": [],
      "source": [
        "Xtst = np.array([[2], [5]])\n",
        "ytst = np.array([[7], [13.1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p5XdVXxaUKd"
      },
      "outputs": [],
      "source": [
        "# Make predictions using the testing set\n",
        "y_pred = reg.predict(Xtst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9SQyi1gkAE4"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKA_vbY_kbGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10D2YqBNMWgi"
      },
      "source": [
        "Show the mean-squared-error (MSE) and R-2 for the new observation predictions. Note that the R-2 here (which is measured on the new observations -- known as the the test set) will most likely differ from the R-2 above (which was measured on the data that we used to generate the regression model -- also know as the training set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEf3_4_6aONj"
      },
      "outputs": [],
      "source": [
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(ytst, y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(ytst, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QqvCH9tZ7aD"
      },
      "outputs": [],
      "source": [
        "# Plot outputs\n",
        "plt.scatter(Xtst, ytst, color=\"green\", label=\"Test\")\n",
        "plt.scatter(X, y, color=\"black\", label=\"Train\")\n",
        "\n",
        "X_test = np.linspace(0, 7, 70)\n",
        "plt.plot(X_test, reg.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
        "\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.xlim((-1, 8))\n",
        "plt.ylim((0, 18))\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rIrkbdeeRyX"
      },
      "source": [
        "The fit for this dataset is quite good.  Now let's look at a less linear dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9IzGyr25Qk1"
      },
      "outputs": [],
      "source": [
        "X = np.array([[1], [4], [0], [3]])\n",
        "y = np.array([[4.7], [17.9], [2.6], [12.3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU7zw-Ke1VHh"
      },
      "source": [
        "**Insert cells to call LinearRegression(), generate the R-2, and print out the coefficient and the intercept, as we did above.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERQ2zgc15kV"
      },
      "source": [
        "Now predict our Y values for new observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh7oL7l76fTO"
      },
      "outputs": [],
      "source": [
        "Xtst = np.array([[2], [7]])\n",
        "ytst = np.array([[6.9], [53.1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70nSW67maLbv"
      },
      "source": [
        ".predict() gives predicted value for new observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZECjZB56wo2"
      },
      "outputs": [],
      "source": [
        "y_pred = reg.predict(Xtst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8uYsfR361Zy"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COjdmOKgefMt"
      },
      "source": [
        "Now compute the mean squared error and R-2 of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAD0COdK69Cz"
      },
      "outputs": [],
      "source": [
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(ytst, y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(ytst, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaVGa70Xy1OR"
      },
      "source": [
        "Such a low R-2 should be reason for concern about the model we are using. Let's visualize our results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrddU1CJ7Cru"
      },
      "outputs": [],
      "source": [
        "# Plot outputs\n",
        "plt.scatter(Xtst, ytst, color=\"green\", label=\"Test\")\n",
        "plt.scatter(X, y, color=\"black\", label=\"Train\")\n",
        "\n",
        "X_test = np.linspace(0, 7, 70)\n",
        "plt.plot(X_test, reg.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
        "\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.xlim((-1, 8))\n",
        "plt.ylim((0, 80))\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRabW3cU2O6f"
      },
      "source": [
        "So, this is obviously not a good fit for the dataset we have used.  Such a small training dataset exposes an issue.  Three points does not give us enough information to derive the true characteristics of the function we are approximating.  With the additional observations, it's apparent that this is not a linear function, so...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKbNXt5etUI"
      },
      "source": [
        "Let's do a polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPhJVTk77h8u"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_reg.fit_transform(X)\n",
        "lin_reg2 = LinearRegression()\n",
        "lin_reg2.fit(X_poly,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJNsclsfzEmo"
      },
      "source": [
        "And now let's visualize the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hAcWEp09GNQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_grid = np.arange(min(X),max(X),0.1)\n",
        "X_grid = X_grid.reshape(len(X_grid),1)\n",
        "\n",
        "plt.scatter(Xtst, ytst, color=\"green\", label=\"Test\")\n",
        "plt.scatter(X, y, color=\"black\", label=\"Train\")\n",
        "X_test = np.linspace(0, 7, 70)\n",
        "plt.plot(X_test, lin_reg2.predict(poly_reg.fit_transform(X_test[:, np.newaxis])), label=\"Model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NRkx38L3O6D"
      },
      "source": [
        "Again, notice a small training dataset is limiting our accuracy, but ... at least our model follows the non-linear behavior of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUx7WtK_e3tY"
      },
      "source": [
        "Let's do some regression on larger, more compled datasets.  This dataset, vehicle miles-per-gallon, is a commonly used datatset for machine learning. \n",
        "The following set of cells pull the dataset into a dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZrq1MQzq2h3"
      },
      "outputs": [],
      "source": [
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_df = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoK43usorRaY"
      },
      "outputs": [],
      "source": [
        "df = raw_df.copy()\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgmtUZX13-jk"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjVBQ4fY3xY-"
      },
      "source": [
        "Look at the dataset to see how many NANs need to be cleaned up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u4IhOjgrahe"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAkfTx2H4H2H"
      },
      "source": [
        "With 392 of 398 entries without NaNs, let's just drop the NaN entries.  \n",
        "**Insert a cell to drop the NaNs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pJLnHTe4RG2"
      },
      "source": [
        "Let's also ignore the country of origin of the vehicle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5Ep9qwXr0H5"
      },
      "outputs": [],
      "source": [
        "df = df.drop('Origin', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhNg3c5SsVKi"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1gZsvRMsZ19"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieWJxx_tfKVD"
      },
      "source": [
        "We will use a Seaborn pair-plot to examine correlation of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeUjaCSksmhj"
      },
      "outputs": [],
      "source": [
        "df_plot = df.iloc[:, 0:7]\n",
        "sns.pairplot(df_plot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77UXlYp8nTMx"
      },
      "source": [
        "It is also helplful to have the numeric correlation coefficients.  \n",
        "**Insert a cell with the .corr() method to print them for your dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDkhR7ZrLVCu"
      },
      "source": [
        "Most of the features we are evaluating have significant correlations with the MPG.  To start, let's just use  Displacement and Horsepower to do the regression.\n",
        "Let's select the subset of the features from our dataframe and pass them to our model building methodology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yDf84K8tM08"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "X=df[['Displacement', 'Horsepower']]\n",
        "\n",
        "# the dependent variable\n",
        "y = df[['MPG']]\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6C0FRJltv5g"
      },
      "outputs": [],
      "source": [
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Here are the coefficients for each variable and the intercept\n",
        "\n",
        "for idx, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFZgKjvNuH95"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoBGI3hg00fL"
      },
      "source": [
        "Sometimes statisticians refer to in_sample and out-of_sample to mean data used to derive the regression (or other model) and the additional data samples used to evaluate the model, repsectively.  In this case it is synonymous with the training set and test set, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5SbTWyOuPMw"
      },
      "outputs": [],
      "source": [
        "in_sampleScore = regression_model.score(X_train, y_train)\n",
        "print(f'In-Sample score = {in_sampleScore}')\n",
        "\n",
        "out_sampleScore = regression_model.score(X_test, y_test)\n",
        "print(f'Out-Sample Score = {out_sampleScore}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFFQwOHOLnhT"
      },
      "source": [
        "Now include polynomial features up to degree 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5BORxqvuaYH"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
        "X_train2 = poly.fit_transform(X_train)\n",
        "X_test2 = poly.fit_transform(X_test)\n",
        "\n",
        "poly_regr = linear_model.LinearRegression()\n",
        "\n",
        "poly_regr.fit(X_train2, y_train)\n",
        "\n",
        "y_pred = poly_regr.predict(X_test2)\n",
        "\n",
        "print(poly_regr.score(X_train2, y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfM00E-uBar4"
      },
      "outputs": [],
      "source": [
        "poly_regr.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjL4ciccHEAv"
      },
      "outputs": [],
      "source": [
        "poly_regr.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SgLu0CqAn8X"
      },
      "source": [
        "The intercept is the w0 or the constant in our fit.  In the coefficient array, the 2nd element is the coefficient for Displacement, 3rd is for HP, 4th is for HPxDisp, 5th is Disp^2, 6th is HP^2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFZTmAZkGTQJ"
      },
      "source": [
        "**Insert a cell with the equation you have found which best predicts vehicle MPG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu5jHnMOLweA"
      },
      "source": [
        "**Now repeat the above using all the features 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year' for the independent variables. Copy cells from above and modify to select the features, train/test split, specify the model, train the model, find and print the in and out of sample scores.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVx0ddzORL8u"
      },
      "source": [
        "**Then do the polynomial degree 2 fit and print the coefficient array, intercept, and R^2 score.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DNucsmoMcbh"
      },
      "source": [
        "You can experiment by trying other combinations of two features to replace horsepower and displacement above -- several cells up.  By looking at the seaborn it may be possible to pick two features which come close to the R-2 that we get with all of the features. If you do that copy cells below for this analysis -- no extra credit will be given for this exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ru2TTChzex"
      },
      "source": [
        "## Part 2: Regression Analysis of Blower Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mToGyp7F3N6d"
      },
      "source": [
        "Now we will look at applying regression models to our blower data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_udfcuCyhjar"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14CkYBw-h7TH"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sq-MrifiBPf"
      },
      "outputs": [],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuz-685DiFIA"
      },
      "outputs": [],
      "source": [
        "!ls drive/MyDrive/ECEN250LeafBlowersClean.csv ## please change this to the directory of your CSV file that you downloaded from Lab 4 module in Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU_kUbxIikXd"
      },
      "outputs": [],
      "source": [
        "# importing dataset\n",
        "df = pd.read_csv('drive/MyDrive/ECEN250LeafBlowersClean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyxDXf_kinzP"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMrHFxvGirWl"
      },
      "source": [
        "**Again we probably want to drop the  source field-- since it has long text just clutters up the dataframe. Insert a cell to accomplish this.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVdfeLiRi7mT"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxxoAM3tjCCi"
      },
      "source": [
        "**We are about to start our modeling -- Make sure that everything except the manufacturer, model, and retail information are numeric:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIjUEZoUjENw"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLNPNw9IjI-k"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNdRrWmTkcE"
      },
      "source": [
        "Let's start at looking at linear regression models for the performance of our blowers.  First let's do a simple regression with voltage as a predictor of hi mph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbaYj-wPjj7F"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc6HITDXUk3B"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "X=df[['volt']]\n",
        "\n",
        "# the dependent variable\n",
        "y = df[['hi mph']]\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P11WEm90VARk"
      },
      "outputs": [],
      "source": [
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Here are the coefficients for each variable and the intercept\n",
        "\n",
        "for idx, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5fi9vSOVH-_"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peHAyM5PVgdZ"
      },
      "source": [
        "Let's check how good our model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoUNa8-XVX7c"
      },
      "outputs": [],
      "source": [
        "in_sampleScore = regression_model.score(X_train, y_train)\n",
        "print(f'In-Sample score = {in_sampleScore}')\n",
        "\n",
        "out_sampleScore = regression_model.score(X_test, y_test)\n",
        "print(f'Out-Sample Score = {out_sampleScore}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzIprAuzVrP_"
      },
      "source": [
        "This is not good at all!  Instead of simple regression, let's do multiple regression and include voltage, hi max rpm, low max rpm, and price!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEKhhp4JWLci"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "X=df[['volt', 'hi cfm', 'price']]\n",
        "# the dependent variable\n",
        "y = df[['hi mph']]\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeWkcNWAWZJY"
      },
      "outputs": [],
      "source": [
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Here are the coefficients for each variable and the intercept\n",
        "\n",
        "for idx, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5ZE9AgPWdg6"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY7UYJdUWi1e"
      },
      "outputs": [],
      "source": [
        "in_sampleScore = regression_model.score(X_train, y_train)\n",
        "print(f'In-Sample score = {in_sampleScore}')\n",
        "\n",
        "out_sampleScore = regression_model.score(X_test, y_test)\n",
        "print(f'Out-Sample Score = {out_sampleScore}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zi1ozZFWpXA"
      },
      "source": [
        "For my dataset, R-2s are only 0.3 to 0.4.  Maybe we need a 2nd degree polynomial fit.  \n",
        "**Insert cells below to do the 2nd degree polynomial fit, predict y values with this model for the testset and print the training and test R2s**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0NvuABXu69"
      },
      "source": [
        "For me this is only a bit better fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjDRp3TkUfSG"
      },
      "source": [
        "NOW: let's look at simple linear regression of price: Start with only the hi mph as a predictor of price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd2hNINVjq_F"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "X=df[['hi mph']]\n",
        "\n",
        "# the dependent variable\n",
        "y = df[['price']]\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-DsBQ6LjwHM"
      },
      "outputs": [],
      "source": [
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Here are the coefficients for each variable and the intercept\n",
        "\n",
        "for idx, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWV_5zPpjzY4"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPTmkK4UCPHa"
      },
      "source": [
        "**Insert a cell with the equation for the linear regression model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeV-zuB6CXox"
      },
      "source": [
        "Let's check how good our model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKFbJcPmj3nZ"
      },
      "outputs": [],
      "source": [
        "in_sampleScore = regression_model.score(X_train, y_train)\n",
        "print(f'In-Sample score = {in_sampleScore}')\n",
        "\n",
        "out_sampleScore = regression_model.score(X_test, y_test)\n",
        "print(f'Out-Sample Score = {out_sampleScore}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm9YMRxR4o0k"
      },
      "source": [
        " Let's see if using a polynomial model for regression works better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGVxqX_qj8hZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
        "X_train2 = poly.fit_transform(X_train)\n",
        "X_test2 = poly.fit_transform(X_test)\n",
        "\n",
        "poly_regr = linear_model.LinearRegression()\n",
        "\n",
        "poly_regr.fit(X_train2, y_train)\n",
        "\n",
        "y_pred = poly_regr.predict(X_test2)\n",
        "\n",
        "#print(y_pred)\n",
        "\n",
        "#In sample (training) R^2 will always improve with the number of variables!\n",
        "\n",
        "print(poly_regr.score(X_train2, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDTy0U8beCWK"
      },
      "source": [
        "Still bad ... try the same for max cfm vs price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIK1Z-jPegu4"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "X=df[['hi cfm']]\n",
        "\n",
        "# the dependent variable\n",
        "y = df[['price']]\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo6t_X_8egu5"
      },
      "outputs": [],
      "source": [
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Here are the coefficients for each variable and the intercept\n",
        "\n",
        "for idx, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[0][idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1xf9dNbegu5"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-3QJM-egu5"
      },
      "source": [
        "**Insert a cell with the equation for the linear regression model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haID4QOKegu6"
      },
      "source": [
        "**Let's check how good our model is. Insert a cell to check the in-sample and out-sample score of the model:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBEL6oytegu6"
      },
      "source": [
        "Let's see if using a polynomial model for regression works better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrXMwmAPegu6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
        "X_train2 = poly.fit_transform(X_train)\n",
        "X_test2 = poly.fit_transform(X_test)\n",
        "\n",
        "poly_regr = linear_model.LinearRegression()\n",
        "\n",
        "poly_regr.fit(X_train2, y_train)\n",
        "\n",
        "y_pred = poly_regr.predict(X_test2)\n",
        "\n",
        "#print(y_pred)\n",
        "\n",
        "#In sample (training) R^2 will always improve with the number of variables!\n",
        "\n",
        "print(poly_regr.score(X_train2, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqkTJ-8egu6"
      },
      "source": [
        "Still bad ... lets try multiple regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlEN2C0Dj90O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r8mqPBE3xjy"
      },
      "source": [
        "**Now do multiple regression for 6 features: 'volt','motor type', 'no batteries', 'hi cfm', 'hi mph', 'weight'. Form the X; do train/test splitting; do the multiple regression; find coefficients; and intercept. Insert cells below similar to the simple regression you just did to accomplish this.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHMIXm3C4mLm"
      },
      "source": [
        "Now do predictions based on your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq8bw2NQkhIt"
      },
      "outputs": [],
      "source": [
        "# Calculate the predicted value for training and test dataset\n",
        "#\n",
        "y_train_pred = regression_model.predict(X_train)\n",
        "y_test_pred = regression_model.predict(X_test)\n",
        "#\n",
        "# Mean Squared Error\n",
        "#\n",
        "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),\n",
        "                mean_squared_error(y_test, y_test_pred)))\n",
        "#\n",
        "# R-Squared\n",
        "#\n",
        "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
        "                r2_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfUD6sN25yXe"
      },
      "source": [
        "For my data, these R-2s were an improvement.  So a multiple linear regression seems to work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vac-qpu6w4n"
      },
      "source": [
        "Now, let's redo this on a scaled data. Let's make a copy of your dataframe with df.copy(), Use StandardScaler(), to scale the dataset, then run a regression model on the scaled dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvm9rAjSkrE7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# make a copy of dataframe\n",
        "scaled_df = df.copy()\n",
        "\n",
        "col_names = ['volt','no batteries','motor type', 'hi cfm', 'hi mph', 'weight', 'price']\n",
        "features = scaled_df[col_names]\n",
        "\n",
        "# Use scaler of choice; here Standard scaler is used\n",
        "scaler = StandardScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "scaled_df[col_names] = features\n",
        "\n",
        "X=scaled_df[ ['volt','no batteries','motor type', 'hi cfm', 'hi mph', 'weight']]\n",
        "\n",
        "\n",
        "# the dependent variable\n",
        "y = scaled_df[['price']]\n",
        "\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwyW8WUg6Q6Y"
      },
      "source": [
        "**Insert a cell to create a model `regression_model`, make a call to the `regression_model.fit()` as above to train our model, and then print the coefficients and intercept**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2aNzsK1k5zP"
      },
      "source": [
        "Notice that with scaled features, we can use coefficients to determine which are the most important features, order by absolute value. My most improtant are weight, no batteries, hi cfm, and hi mph.  Depending on the data you gathered and trained your model on, you may have different order of importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inBDpqH4k1OX"
      },
      "outputs": [],
      "source": [
        "intercept = regression_model.intercept_[0]\n",
        "print(f\"The intercept for our model is {regression_model.intercept_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_qh8TLEk9gF"
      },
      "outputs": [],
      "source": [
        "# Calculate the predicted value for training and test dataset\n",
        "#\n",
        "y_train_pred = regression_model.predict(X_train)\n",
        "y_test_pred = regression_model.predict(X_test)\n",
        "#\n",
        "# Mean Squared Error\n",
        "#\n",
        "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),\n",
        "                mean_squared_error(y_test, y_test_pred)))\n",
        "#\n",
        "# R-Squared\n",
        "#\n",
        "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
        "                r2_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyWKBjelFXZ"
      },
      "source": [
        "Goodness of fit for me is ok-- about 0.7. Let's add the polynomial features up to degree 2 to see if we get better results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDd4INlElUue"
      },
      "source": [
        "Now, let's add the polynomial features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeBIgXFBXYVF"
      },
      "outputs": [],
      "source": [
        "# make a copy of dataframe\n",
        "scaled_df = df.copy()\n",
        "\n",
        "col_names = ['volt','no batteries','motor type', 'hi cfm', 'hi mph', 'weight', 'price']\n",
        "features = scaled_df[col_names]\n",
        "\n",
        "# Use scaler of choice; here Standard scaler is used\n",
        "scaler = StandardScaler().fit(features.values)\n",
        "features = scaler.transform(features.values)\n",
        "\n",
        "scaled_df[col_names] = features\n",
        "\n",
        "X=scaled_df[ ['volt','no batteries','motor type', 'hi cfm', 'hi mph', 'weight']]\n",
        "\n",
        "\n",
        "# the dependent variable\n",
        "y = scaled_df[['price']]\n",
        "\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu27mRFNXxXu"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
        "X_train2 = poly.fit_transform(X_train)\n",
        "X_test2 = poly.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln9oy3xT79uq"
      },
      "source": [
        "Now by using the PolynomialFeatures() prior to the fit-transform regression model training, we have added the polynomial terms up to degree 2 in this case. **Insert a cell to fit a new model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLtrpLbrlld2"
      },
      "outputs": [],
      "source": [
        "# Calculate the predicted value for training and test dataset\n",
        "#\n",
        "y_train_pred = regression_model.predict(X_train2)\n",
        "y_test_pred = regression_model.predict(X_test2)\n",
        "#\n",
        "# Mean Squared Error\n",
        "#\n",
        "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),\n",
        "                mean_squared_error(y_test, y_test_pred)))\n",
        "#\n",
        "# R-Squared\n",
        "#\n",
        "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
        "                r2_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHLHBQyl9OQf"
      },
      "source": [
        "Let's look at the features in more detail by using seaborn pair-plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Y11JhQ9hyC"
      },
      "outputs": [],
      "source": [
        "df_plot = df.iloc[:, 3:15]\n",
        "sns.pairplot(df_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ib8e-X9ruf"
      },
      "source": [
        "For my dataset, est max torque, no batteries, hi max rpm all highly correlate. Recall, that highly correlated features because they move together, capture the same variance in the dataset.  There are techniques that are optimized to capture the most variance with the fewest features.  We will see these later in the semester.\n",
        "\n",
        "For now, let's use another machine learning model to determine the relative importance of each of our features in our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJmNLCDfrDH8"
      },
      "source": [
        "Let's use Random forest to validate most important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33R5-QkTrEY7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import scale\n",
        "import matplotlib.pyplot as plt\n",
        "#from sklearn import set_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BsRxe38rLs6"
      },
      "outputs": [],
      "source": [
        "# independant variables\n",
        "\n",
        "X=df[['volt','no batteries','bat Ahr', 'bat lb', 'motor type', 'sound rating','hi cfm', 'lo cfm', 'hi mph', 'lo mph','weight']]\n",
        "\n",
        "\n",
        "X=scale(X)\n",
        "\n",
        "\n",
        "# the dependent variable\n",
        "y = df[['price']]\n",
        "y = scale (y)\n",
        "\n",
        "# Split X and y into training and test set in 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5uCaKI0rM6v"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF8pu3v--hgU"
      },
      "source": [
        "We are now passing our dataset to a Random Forest Regressor -- an alternative to Linear Regression.  We will study Random Forests in a few weeks -- here we will use a characteristic of Random Forests, their ability to rate feature importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YAO72PB-hKD"
      },
      "source": [
        "We just change our model from a LinearRegressor to a RandomForestRegressor!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE9NVY35rSXs"
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor()\n",
        "print(rfr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCMLa9WTrTV4"
      },
      "outputs": [],
      "source": [
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "score = rfr.score(X_train, y_train)\n",
        "print(\"R-squared:\", score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s57i5PXQrYTa"
      },
      "outputs": [],
      "source": [
        "ypred = rfr.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, ypred)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", np.sqrt(mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZgZRXNcrgO-"
      },
      "outputs": [],
      "source": [
        "rfr.feature_importances_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0SwA6RpvOrW"
      },
      "source": [
        "X features in order are [['volt','no batteries','bat Ahr', 'bat lb', 'motor type', 'sound rating', 'hi cfm', 'lo cfm, 'hi mph', 'lo mph', 'weight']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a8t98vPrpm_"
      },
      "source": [
        "Most important for the data that I used for this model are: hi cfm, no batteries (both very important), then weight, hi mph (medium importance) then motor type and voltage (low importance).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xST0o2u0Zb71"
      },
      "source": [
        "Lab 4 is now complete.  Make sure all cells are visible and have been run (rerun if necessary).\n",
        "\n",
        "The code below converts the ipynb file to PDF, and saves it to where this .ipynb file is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NOTEBOOK_PATH = # Enter here, the path to your notebook file, e.g. \"/content/drive/MyDrive/ECEN250/ECEN250_Lab4.ipynb\". Do not change the lines below, and make sure you do not have multiple notebooks with the same path.\n",
        "! pip install playwright\n",
        "! jupyter nbconvert --to webpdf --allow-chromium-download \"$NOTEBOOK_PATH\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download your notebook as an .ipynb file, then upload it along with the PDF file (saved in the same Google Drive folder as this notebook) to Canvas for Lab 4. Make sure that the PDF file matches your .ipynb file."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
